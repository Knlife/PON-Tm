{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 导入模块",
   "id": "267ed3bc7805392d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T23:03:52.712400Z",
     "start_time": "2024-06-12T23:03:52.709043Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBRegressor\n",
    "os.chdir(\"D:/WorkPath/PycharmProjects/MutTm-pred\")\n",
    "from Dataset.Process4Dataset.DatasetCeator4PonDT import Dataset4MutTm"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 25",
   "id": "fd1c6d91e8b7ecea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:08:02.269755Z",
     "start_time": "2024-06-12T23:05:11.458060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据集生成\n",
    "dataset = Dataset4MutTm(package_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\\Process4Dataset\",\n",
    "                          train_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\"\n",
    "                                             r\"\\BasicData\\PonDB\\Common\\PonDB.csv\",\n",
    "                          test_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\"\n",
    "                                            r\"\\BasicData\\ProThermDB\\Common\\excllent_ProThermDB_Testing.csv\",\n",
    "                          training_version=\"PonDB_Common\",\n",
    "                          testing_version=\"ProThermDBTest_Common\",\n",
    "                          selected_columns=[\"UniProt_ID\", \"Mutation\", \"ΔTm\"],\n",
    "                          features=[\"neighbor\", \"aaindex\", \"group\", \"param\",\n",
    "                                    \"sift4g\", \"hydrop\", \"context_embedding\"],\n",
    "                          context_length=25,\n",
    "                          embedding_model_path=\"DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D\",\n",
    "                          embedding_model_name=\"ESM-2-150M\",\n",
    "                          embedding_method=\"add\")\n",
    "train_feature = np.array(dataset.train_feature_set)\n",
    "train_label = np.array(dataset.train_label_set).ravel()\n",
    "\n",
    "# 特征筛选\n",
    "best_rfe = RFE(XGBRegressor(),\n",
    "              n_features_to_select=200,\n",
    "              step=10,\n",
    "              verbose=False)\n",
    "best_rfe.fit(train_feature, train_label)\n",
    "\n",
    "# 模型训练\n",
    "best_model = XGBRegressor(max_depth=23,\n",
    "                          min_child_weight=7,\n",
    "                          gamma=0.67,\n",
    "                          subsample=0.83,\n",
    "                          colsample_bytree=0.93,\n",
    "                          alpha=0.0175)\n",
    "best_model.fit(best_rfe.transform(train_feature), train_label)\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(best_rfe, \"ModelSave/rfe_25_Common.pkl\")\n",
    "joblib.dump(best_model, \"ModelSave/model_25_Common.pkl\")"
   ],
   "id": "23554ca712827c09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用设备：  NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "===正在从训练集版本为PonDB_Common、测试集版本为ProThermDBTest_Common的原始数据集中进行数据清洗和生物特征提取工作===\n",
      "1.预处理训练集数据...\n",
      "-删除数据缺失行及非法行共计0行\n",
      "-丢弃pH/Tm的缺失值\n",
      "-前一数据集采用了后一数据集中的0条数据，现已删除\n",
      "-获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "-删除了25个UniProtID无法获取序列的数据\n",
      "-删除了4条非法长度的数据，当前蛋白质长度被限制在(25, 5000)\n",
      "-删除条792个突变位点对应错误的数据\n",
      "2.预处理测试集数据...\n",
      "-删除数据缺失行及非法行共计0行\n",
      "-丢弃pH/Tm的缺失值\n",
      "-获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "-删除了0个UniProtID无法获取序列的数据\n",
      "-删除了0条非法长度的数据，当前蛋白质长度被限制在(25, 5000)\n",
      "-删除条11个突变位点对应错误的数据\n",
      "3.为训练集数据提取生物特征...\n",
      "-获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[aaindex特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[group特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[sift4g]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[param]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[pssm]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[hydrop]特征.....该数据集已经经过处理，直接使用缓存文件\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-获取[context_embedding]特征,该特征没有缓存文件，直接生成...\n",
      "嵌入模型后显存使用量:  1.1186332702636719\n",
      "-释放模型后显存用量: 0.5632882118225098\n",
      "4.为测试集数据提取生物特征...\n",
      "-获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[aaindex特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[group特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[sift4g]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[param]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[pssm]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[hydrop]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[context_embedding]特征,该特征没有缓存文件，直接生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型后显存使用量:  1.1186332702636719\n",
      "-释放模型后显存用量: 0.5632882118225098\n",
      "6.从全数据集中提取生物特征集、标签集和基本信息集...\n",
      "7.数据清洗和生物特征提取工作完成==>当前显存用量:0.5630879402160645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ModelSave/model_25_Common.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 50",
   "id": "5186bedbf1e1886e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T04:24:57.254302Z",
     "start_time": "2024-06-13T04:22:00.619832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据集生成\n",
    "dataset = Dataset4MutTm(package_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\\Process4Dataset\",\n",
    "                          train_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\"\n",
    "                                             r\"\\BasicData\\PonDB\\Common\\PonDB.csv\",\n",
    "                          test_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\"\n",
    "                                            r\"\\BasicData\\ProThermDB\\Common\\excllent_ProThermDB_Testing.csv\",\n",
    "                          training_version=\"PonDB_Common\",\n",
    "                          testing_version=\"ProThermDBTest_Common\",\n",
    "                          selected_columns=[\"UniProt_ID\", \"Mutation\", \"ΔTm\"],\n",
    "                          features=[\"neighbor\", \"aaindex\", \"group\", \"param\",\n",
    "                                    \"sift4g\", \"hydrop\", \"context_embedding\"],\n",
    "                          context_length=50,\n",
    "                          embedding_model_path=\"DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D\",\n",
    "                          embedding_model_name=\"ESM-2-150M\",\n",
    "                          embedding_method=\"add\")\n",
    "train_feature = np.array(dataset.train_feature_set)\n",
    "train_label = np.array(dataset.train_label_set).ravel()\n",
    "\n",
    "# 特征筛选\n",
    "best_rfe = RFE(XGBRegressor(),\n",
    "              n_features_to_select=200,\n",
    "              step=10,\n",
    "              verbose=False)\n",
    "best_rfe.fit(train_feature, train_label)\n",
    "\n",
    "# 模型训练\n",
    "best_model = XGBRegressor(max_depth=23,\n",
    "                          min_child_weight=7,\n",
    "                          gamma=0.67,\n",
    "                          subsample=0.83,\n",
    "                          colsample_bytree=0.93,\n",
    "                          alpha=0.0175)\n",
    "best_model.fit(best_rfe.transform(train_feature), train_label)\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(best_rfe, \"ModelSave/rfe_50_Common.pkl\")\n",
    "joblib.dump(best_model, \"ModelSave/model_50_Common.pkl\")"
   ],
   "id": "d5b99207261ea6da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用设备：  NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "===正在从训练集版本为PonDB_Common、测试集版本为ProThermDBTest_Common的原始数据集中进行数据清洗和生物特征提取工作===\n",
      "1.预处理训练集数据...\n",
      "-删除数据缺失行及非法行共计0行\n",
      "-丢弃pH/Tm的缺失值\n",
      "-前一数据集采用了后一数据集中的0条数据，现已删除\n",
      "-获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "-删除了25个UniProtID无法获取序列的数据\n",
      "-删除了4条非法长度的数据，当前蛋白质长度被限制在(50, 5000)\n",
      "-删除条792个突变位点对应错误的数据\n",
      "2.预处理测试集数据...\n",
      "-删除数据缺失行及非法行共计0行\n",
      "-丢弃pH/Tm的缺失值\n",
      "-获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "-删除了0个UniProtID无法获取序列的数据\n",
      "-删除了0条非法长度的数据，当前蛋白质长度被限制在(50, 5000)\n",
      "-删除条11个突变位点对应错误的数据\n",
      "3.为训练集数据提取生物特征...\n",
      "-获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[aaindex特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[group特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[sift4g]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[param]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[pssm]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[hydrop]特征.....该数据集已经经过处理，直接使用缓存文件\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-获取[context_embedding]特征,该特征没有缓存文件，直接生成...\n",
      "嵌入模型后显存使用量:  1.1186332702636719\n",
      "-释放模型后显存用量: 0.5634598731994629\n",
      "4.为测试集数据提取生物特征...\n",
      "-获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[aaindex特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[group特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[sift4g]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[param]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[pssm]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[hydrop]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[context_embedding]特征,该特征没有缓存文件，直接生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型后显存使用量:  1.1186332702636719\n",
      "-释放模型后显存用量: 0.5634598731994629\n",
      "6.从全数据集中提取生物特征集、标签集和基本信息集...\n",
      "7.数据清洗和生物特征提取工作完成==>当前显存用量:0.5630879402160645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ModelSave/model_50_Common.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 100",
   "id": "4faf5bab0fb8da54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:25:28.050016Z",
     "start_time": "2024-06-12T23:22:42.752698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据集生成\n",
    "dataset = Dataset4MutTm(package_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\\Process4Dataset\",\n",
    "                          train_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\"\n",
    "                                             r\"\\BasicData\\PonDB\\Common\\PonDB.csv\",\n",
    "                          test_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\"\n",
    "                                            r\"\\BasicData\\ProThermDB\\Common\\excllent_ProThermDB_Testing.csv\",\n",
    "                          training_version=\"PonDB_Common\",\n",
    "                          testing_version=\"ProThermDBTest_Common\",\n",
    "                          selected_columns=[\"UniProt_ID\", \"Mutation\", \"ΔTm\"],\n",
    "                          features=[\"neighbor\", \"aaindex\", \"group\", \"param\",\n",
    "                                    \"sift4g\", \"hydrop\", \"context_embedding\"],\n",
    "                          context_length=100,\n",
    "                          embedding_model_path=\"DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D\",\n",
    "                          embedding_model_name=\"ESM-2-150M\",\n",
    "                          embedding_method=\"add\")\n",
    "train_feature = np.array(dataset.train_feature_set)\n",
    "train_label = np.array(dataset.train_label_set).ravel()\n",
    "\n",
    "# 特征筛选\n",
    "best_rfe = RFE(XGBRegressor(),\n",
    "              n_features_to_select=200,\n",
    "              step=10,\n",
    "              verbose=False)\n",
    "best_rfe.fit(train_feature, train_label)\n",
    "\n",
    "# 模型训练\n",
    "best_model = XGBRegressor(max_depth=23,\n",
    "                          min_child_weight=7,\n",
    "                          gamma=0.67,\n",
    "                          subsample=0.83,\n",
    "                          colsample_bytree=0.93,\n",
    "                          alpha=0.0175)\n",
    "best_model.fit(best_rfe.transform(train_feature), train_label)\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(best_rfe, \"ModelSave/rfe_100_Common.pkl\")\n",
    "joblib.dump(best_model, \"ModelSave/model_100_Common.pkl\")"
   ],
   "id": "9a4d8c849264b525",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用设备：  NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "===正在从训练集版本为PonDB_Common、测试集版本为ProThermDBTest_Common的原始数据集中进行数据清洗和生物特征提取工作===\n",
      "1.预处理训练集数据...\n",
      "-删除数据缺失行及非法行共计0行\n",
      "-丢弃pH/Tm的缺失值\n",
      "-前一数据集采用了后一数据集中的0条数据，现已删除\n",
      "-获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "-删除了25个UniProtID无法获取序列的数据\n",
      "-删除了285条非法长度的数据，当前蛋白质长度被限制在(100, 5000)\n",
      "-删除条758个突变位点对应错误的数据\n",
      "2.预处理测试集数据...\n",
      "-删除数据缺失行及非法行共计0行\n",
      "-丢弃pH/Tm的缺失值\n",
      "-获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "-删除了0个UniProtID无法获取序列的数据\n",
      "-删除了32条非法长度的数据，当前蛋白质长度被限制在(100, 5000)\n",
      "-删除条10个突变位点对应错误的数据\n",
      "3.为训练集数据提取生物特征...\n",
      "-获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[aaindex特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[group特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[sift4g]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[param]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[pssm]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[hydrop]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[context_embedding]特征,该特征没有缓存文件，直接生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型后显存使用量:  1.1186332702636719\n",
      "-释放模型后显存用量: 0.5638318061828613\n",
      "4.为测试集数据提取生物特征...\n",
      "-获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[aaindex特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[group特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[sift4g]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[param]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[pssm]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[hydrop]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[context_embedding]特征,该特征没有缓存文件，直接生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型后显存使用量:  1.1186332702636719\n",
      "-释放模型后显存用量: 0.5638318061828613\n",
      "6.从全数据集中提取生物特征集、标签集和基本信息集...\n",
      "7.数据清洗和生物特征提取工作完成==>当前显存用量:0.5630879402160645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ModelSave/model_100_Common.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 200",
   "id": "2aeb482e17dae53f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:27:56.479769Z",
     "start_time": "2024-06-12T23:25:28.050016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据集生成\n",
    "dataset = Dataset4MutTm(package_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\\Process4Dataset\",\n",
    "                          train_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\"\n",
    "                                             r\"\\BasicData\\PonDB\\Common\\PonDB.csv\",\n",
    "                          test_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\"\n",
    "                                            r\"\\BasicData\\ProThermDB\\Common\\excllent_ProThermDB_Testing.csv\",\n",
    "                          training_version=\"PonDB_Common\",\n",
    "                          testing_version=\"ProThermDBTest_Common\",\n",
    "                          selected_columns=[\"UniProt_ID\", \"Mutation\", \"ΔTm\"],\n",
    "                          features=[\"neighbor\", \"aaindex\", \"group\", \"param\",\n",
    "                                    \"sift4g\", \"hydrop\", \"context_embedding\"],\n",
    "                          context_length=200,\n",
    "                          embedding_model_path=\"DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D\",\n",
    "                          embedding_model_name=\"ESM-2-150M\",\n",
    "                          embedding_method=\"add\")\n",
    "train_feature = np.array(dataset.train_feature_set)\n",
    "train_label = np.array(dataset.train_label_set).ravel()\n",
    "\n",
    "# 特征筛选\n",
    "best_rfe = RFE(XGBRegressor(),\n",
    "              n_features_to_select=200,\n",
    "              step=10,\n",
    "              verbose=False)\n",
    "best_rfe.fit(train_feature, train_label)\n",
    "\n",
    "# 模型训练\n",
    "best_model = XGBRegressor(max_depth=23,\n",
    "                          min_child_weight=7,\n",
    "                          gamma=0.67,\n",
    "                          subsample=0.83,\n",
    "                          colsample_bytree=0.93,\n",
    "                          alpha=0.0175)\n",
    "best_model.fit(best_rfe.transform(train_feature), train_label)\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(best_rfe, \"ModelSave/rfe_200_Common.pkl\")\n",
    "joblib.dump(best_model, \"ModelSave/model_200_Common.pkl\")"
   ],
   "id": "8a2066a94f071a23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用设备：  NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "===正在从训练集版本为PonDB_Common、测试集版本为ProThermDBTest_Common的原始数据集中进行数据清洗和生物特征提取工作===\n",
      "1.预处理训练集数据...\n",
      "-删除数据缺失行及非法行共计0行\n",
      "-丢弃pH/Tm的缺失值\n",
      "-前一数据集采用了后一数据集中的0条数据，现已删除\n",
      "-获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "-删除了25个UniProtID无法获取序列的数据\n",
      "-删除了1452条非法长度的数据，当前蛋白质长度被限制在(200, 5000)\n",
      "-删除条339个突变位点对应错误的数据\n",
      "2.预处理测试集数据...\n",
      "-删除数据缺失行及非法行共计0行\n",
      "-丢弃pH/Tm的缺失值\n",
      "-获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "-删除了0个UniProtID无法获取序列的数据\n",
      "-删除了109条非法长度的数据，当前蛋白质长度被限制在(200, 5000)\n",
      "-删除条6个突变位点对应错误的数据\n",
      "3.为训练集数据提取生物特征...\n",
      "-获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[aaindex特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[group特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[sift4g]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[param]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[pssm]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[hydrop]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[context_embedding]特征,该特征没有缓存文件，直接生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型后显存使用量:  1.1186332702636719\n",
      "-释放模型后显存用量: 0.564547061920166\n",
      "4.为测试集数据提取生物特征...\n",
      "-获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[aaindex特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[group特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[sift4g]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[param]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[pssm]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[hydrop]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[context_embedding]特征,该特征没有缓存文件，直接生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型后显存使用量:  1.1186332702636719\n",
      "-释放模型后显存用量: 0.564547061920166\n",
      "6.从全数据集中提取生物特征集、标签集和基本信息集...\n",
      "7.数据清洗和生物特征提取工作完成==>当前显存用量:0.5630879402160645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ModelSave/model_200_Common.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 500",
   "id": "ec00b3d6dda7f41d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:29:35.471092Z",
     "start_time": "2024-06-12T23:27:56.479769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据集生成\n",
    "dataset = Dataset4MutTm(package_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\\Process4Dataset\",\n",
    "                          train_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\"\n",
    "                                             r\"\\BasicData\\PonDB\\Common\\PonDB.csv\",\n",
    "                          test_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\"\n",
    "                                            r\"\\BasicData\\ProThermDB\\Common\\excllent_ProThermDB_Testing.csv\",\n",
    "                          training_version=\"PonDB_Common\",\n",
    "                          testing_version=\"ProThermDBTest_Common\",\n",
    "                          selected_columns=[\"UniProt_ID\", \"Mutation\", \"ΔTm\"],\n",
    "                          features=[\"neighbor\", \"aaindex\", \"group\", \"param\",\n",
    "                                    \"sift4g\", \"hydrop\", \"context_embedding\"],\n",
    "                          context_length=500,\n",
    "                          embedding_model_path=\"DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D\",\n",
    "                          embedding_model_name=\"ESM-2-150M\",\n",
    "                          embedding_method=\"add\")\n",
    "train_feature = np.array(dataset.train_feature_set)\n",
    "train_label = np.array(dataset.train_label_set).ravel()\n",
    "\n",
    "# 特征筛选\n",
    "best_rfe = RFE(XGBRegressor(),\n",
    "              n_features_to_select=200,\n",
    "              step=10,\n",
    "              verbose=False)\n",
    "best_rfe.fit(train_feature, train_label)\n",
    "\n",
    "# 模型训练\n",
    "best_model = XGBRegressor(max_depth=23,\n",
    "                          min_child_weight=7,\n",
    "                          gamma=0.67,\n",
    "                          subsample=0.83,\n",
    "                          colsample_bytree=0.93,\n",
    "                          alpha=0.0175)\n",
    "best_model.fit(best_rfe.transform(train_feature), train_label)\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(best_rfe, \"ModelSave/rfe_500_Common.pkl\")\n",
    "joblib.dump(best_model, \"ModelSave/model_500_Common.pkl\")"
   ],
   "id": "75911bb764f920db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用设备：  NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "===正在从训练集版本为PonDB_Common、测试集版本为ProThermDBTest_Common的原始数据集中进行数据清洗和生物特征提取工作===\n",
      "1.预处理训练集数据...\n",
      "-删除数据缺失行及非法行共计0行\n",
      "-丢弃pH/Tm的缺失值\n",
      "-前一数据集采用了后一数据集中的0条数据，现已删除\n",
      "-获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "-删除了25个UniProtID无法获取序列的数据\n",
      "-删除了2921条非法长度的数据，当前蛋白质长度被限制在(500, 5000)\n",
      "-删除条118个突变位点对应错误的数据\n",
      "2.预处理测试集数据...\n",
      "-删除数据缺失行及非法行共计0行\n",
      "-丢弃pH/Tm的缺失值\n",
      "-获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "-删除了0个UniProtID无法获取序列的数据\n",
      "-删除了229条非法长度的数据，当前蛋白质长度被限制在(500, 5000)\n",
      "-删除条4个突变位点对应错误的数据\n",
      "3.为训练集数据提取生物特征...\n",
      "-获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[aaindex特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[group特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[sift4g]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[param]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[pssm]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[hydrop]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[context_embedding]特征,该特征没有缓存文件，直接生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型后显存使用量:  1.1186332702636719\n",
      "-释放模型后显存用量: 0.5666928291320801\n",
      "4.为测试集数据提取生物特征...\n",
      "-获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[aaindex特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[group特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[sift4g]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[param]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[pssm]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[hydrop]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "-获取[context_embedding]特征,该特征没有缓存文件，直接生成...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型后显存使用量:  1.1186332702636719\n",
      "-释放模型后显存用量: 0.5666928291320801\n",
      "6.从全数据集中提取生物特征集、标签集和基本信息集...\n",
      "7.数据清洗和生物特征提取工作完成==>当前显存用量:0.5630879402160645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ModelSave/model_500_Common.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
