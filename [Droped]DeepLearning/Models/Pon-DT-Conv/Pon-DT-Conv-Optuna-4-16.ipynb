{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 导入模块",
   "id": "10b83f72697fd8e7"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-16T14:12:31.625748Z",
     "start_time": "2024-04-16T14:12:31.620741Z"
    }
   },
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import logging\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "from torch import optim\n",
    "import math\n",
    "from torch.nn import init, MultiheadAttention\n",
    "from torch.nn import functional as F\n",
    "\n",
    "os.chdir(\"D:/WorkPath/PycharmProjects/MutTm-pred\")\n",
    "from DeepLearning.Util import (PonDataset, PonMetrics, EarlyStopping, logger_init, embedding_dataset_creator_full_length,\n",
    "                               embedding_model_getter)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 全局变量",
   "id": "cc26daf6c0cad0c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:04:48.814546Z",
     "start_time": "2024-04-16T11:02:01.066520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "project_path = \"D:/WorkPath/PycharmProjects/MutTm-pred\"\n",
    "os.chdir(project_path)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# region train&test dataset\n",
    "from Dataset.Process4Dataset.DatasetCeator4PonDT import Dataset4MutTm\n",
    "dataset = Dataset4MutTm(package_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\\Process4Dataset\",\n",
    "                        train_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\\BasicData\\ProThermDB\\Common\\excllent_ProThermDB_Training.csv\",\n",
    "                        test_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\\BasicData\\ProThermDB\\Common\\excllent_ProThermDB_Testing.csv\",\n",
    "                        training_version=\"ProThermDB_Common\",\n",
    "                        testing_version=\"ProThermDBTest_Common\",\n",
    "                        selected_columns=[\"UniProt_ID\", \"Mutation\", \"ΔTm\"],\n",
    "                        mult_mode=\"Average\",\n",
    "                        features=[\"neighbor\"],\n",
    "                        R_path=r\"C:\\Program Files\\R\\R-4.3.2\",\n",
    "                        context_length=200)\n",
    "embedding_model_path = \"DeepLearning/EmbeddingModels/ESM-2/esm2_t33_650M_UR50D\"\n",
    "embedding_model_name = \"ESM-2-650M\"\n",
    "embedding_tokenizer, embedding_model = embedding_model_getter(embedding_model_path,\n",
    "                                                              embedding_model_name,\n",
    "                                                              device)\n",
    "train_dataset, test_dataset = embedding_dataset_creator_full_length(df=dataset,\n",
    "                                                                    embedding_model_name=embedding_model_name,\n",
    "                                                                    model=embedding_model,\n",
    "                                                                    tokenizer=embedding_tokenizer,\n",
    "                                                                    device=device)\n",
    "del embedding_model, embedding_tokenizer\n",
    "# endregion"
   ],
   "id": "6829c987c2eb7cc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===正在从训练集版本为ProThermDB_Common、训练集版本为ProThermDBTest_Common的原始数据集中进行数据清洗和生物特征提取工作===\n",
      "1.预处理训练集数据...\n",
      "删除数据缺失行及非法行共计0行\n",
      "丢弃pH/Tm的缺失值\n",
      "前一数据集采用了后一数据集中的0条数据，现已删除\n",
      "获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "删除了1031个非法长度的蛋白质，当前蛋白质长度被限制在(200, 5000)\n",
      "2.预处理测试集数据...\n",
      "删除数据缺失行及非法行共计0行\n",
      "丢弃pH/Tm的缺失值\n",
      "获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "删除了109个非法长度的蛋白质，当前蛋白质长度被限制在(200, 5000)\n",
      "3.为训练集数据提取生物特征...\n",
      "获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "4.为测试集数据提取生物特征...\n",
      "获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "6.从全数据集中提取生物特征集、标签集和基本信息集...\n",
      "7.数据清洗和生物特征提取工作完成==>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at DeepLearning/EmbeddingModels/ESM-2/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 4/4 [02:44<00:00, 41.05s/it]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 网络模块",
   "id": "4ba6f8bbe087263f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T14:29:52.584468Z",
     "start_time": "2024-04-16T14:29:52.576638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ESM650M_ConvNet_Sub(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 trial):\n",
    "        super(ESM650M_ConvNet_Sub, self).__init__()\n",
    "        dropout_rate = trial.suggest_float(\"dropout\", 0.2, 0.7)\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            torch.nn.Conv1d(1, 8, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(8),\n",
    "            torch.nn.Conv1d(8, 32, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "        )\n",
    "        self.fc_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1280 * 32, 128),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, wild_embedding, mutant_embedding):\n",
    "        output = torch.sub(wild_embedding, mutant_embedding)\n",
    "        output = self.conv_layer(output)\n",
    "        output = self.fc_layer(output.reshape(output.shape[0], -1))\n",
    "        return output\n",
    "\n",
    "\n",
    "class ESM650M_ConvNet_Comb(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 trial):\n",
    "        super(ESM650M_ConvNet_Comb, self).__init__()\n",
    "        dropout_rate = trial.suggest_float(\"dropout\", 0.2, 0.7)\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            torch.nn.Conv1d(1, 8, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(8),\n",
    "            torch.nn.Conv1d(8, 32, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "        )\n",
    "        self.fc_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2560 * 32, 1024),\n",
    "            torch.nn.Linear(1024, 128),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, wild_embedding, mutant_embedding):\n",
    "        output = torch.concat([wild_embedding, mutant_embedding], dim=2)\n",
    "        output = self.conv_layer(output)\n",
    "        output = self.fc_layer(output.reshape(output.shape[0], -1))\n",
    "        return output\n",
    "\n",
    "\n",
    "class ESM650M_AttentionNet_Sub(nn.Module):\n",
    "    def __init__(self,\n",
    "                 trial):\n",
    "        super(ESM650M_AttentionNet_Sub, self).__init__()\n",
    "        dropout_rate_attention = trial.suggest_float(\"dropout\", 0.2, 0.7)\n",
    "        dropout_rate_bn = trial.suggest_float(\"dropout\", 0.2, 0.7)\n",
    "        num_heads = trial.suggest_categorical(\"num_heads\", [1, 2, 4, 8])\n",
    "        bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "        self.attention_module = MultiheadAttention(embed_dim=1280,\n",
    "                                                   num_heads=num_heads,\n",
    "                                                   bias=bias,\n",
    "                                                   dropout=dropout_rate_attention)\n",
    "        self.middle_module = nn.Sequential(\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(1280),\n",
    "            nn.Dropout(dropout_rate_bn)\n",
    "        )\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(1280, 256, dtype=torch.float32), nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128, dtype=torch.float32), nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 1, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    def forward(self, wild_embedding, mutant_embedding):\n",
    "        output = torch.sub(wild_embedding, mutant_embedding)\n",
    "        output, attention = self.attention_module(output, output, output)\n",
    "        output = self.middle_module(output.view(-1, output.shape[-1]))\n",
    "        output = self.fc_layer(output.reshape(output.shape[0], -1))\n",
    "        return output"
   ],
   "id": "4e450cde1c349e32",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 定义optuna调优参数方法",
   "id": "7cd7a4c5316cf5a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T14:50:25.693041Z",
     "start_time": "2024-04-16T14:31:48.133911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective(trial, optuna_dataset):\n",
    "    # region 训练参数\n",
    "    model = ESM650M_AttentionNet_Sub(trial).to(device)\n",
    "    params = {\n",
    "        \"optimizer_name\": trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
    "        \"learning_rate\": trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-5, 1e-1, log=True),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [32, 64]),\n",
    "    }\n",
    "    loss_fn_name = \"MAE\"\n",
    "    optimizer = getattr(optim, params[\"optimizer_name\"])(model.parameters(),\n",
    "                                                         lr=params[\"learning_rate\"],\n",
    "                                                         weight_decay=params[\"weight_decay\"])\n",
    "    loss_fn = nn.L1Loss(reduction=\"mean\") if loss_fn_name == \"MAE\" else nn.MSELoss()\n",
    "\n",
    "    # 加载并分割训练/验证集\n",
    "    train_index, valid_index = train_test_split(range(len(optuna_dataset)), test_size=0.1, random_state=42)\n",
    "    train_fold, val_fold = optuna_dataset.subDataset(train_index), optuna_dataset.subDataset([valid_index])\n",
    "    trainLoader = DataLoader(dataset=train_fold, batch_size=params[\"batch_size\"], shuffle=True, drop_last=True)\n",
    "    validateLoader = DataLoader(dataset=val_fold, batch_size=params[\"batch_size\"], shuffle=True, drop_last=True)\n",
    "    # endregion\n",
    "\n",
    "    # region 模型训练\n",
    "    # 设定模型训练参数(回调点、早停点参数等)\n",
    "    model = model.to(device)\n",
    "    loss_fn = loss_fn.to(device)\n",
    "\n",
    "    min_loss = 10.0\n",
    "    # 训练/验证\n",
    "    for epoch in range(400):\n",
    "\n",
    "        # region Training\n",
    "        train_loss = 0.0\n",
    "        train_steps = 0\n",
    "        model.train()\n",
    "        for wild_embedding, mutant_embedding, bio, label in trainLoader:\n",
    "            # 载入GPU\n",
    "            wild_embedding = wild_embedding.to(device)\n",
    "            mutant_embedding = mutant_embedding.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(wild_embedding, mutant_embedding)  # 预测模型\n",
    "            running_loss = loss_fn(output, label)  # 损失函数并运行计算梯度\n",
    "\n",
    "            optimizer.zero_grad()  # 优化器梯度清零\n",
    "            running_loss.requires_grad_(True)  # 允许梯度\n",
    "            running_loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 重置参数\n",
    "            train_loss += running_loss.item()\n",
    "            train_steps += 1\n",
    "\n",
    "        # endregion\n",
    "\n",
    "        # region Validation\n",
    "        valid_loss = 0.0\n",
    "        valid_steps = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for wild_embedding, mutant_embedding, bio, label in validateLoader:\n",
    "                # 载入GPU\n",
    "                wild_embedding = wild_embedding.to(device)\n",
    "                mutant_embedding = mutant_embedding.to(device)\n",
    "                label = label.to(device)\n",
    "                output = model(wild_embedding, mutant_embedding)  # 预测模型\n",
    "                running_loss = loss_fn(output, label)  # 损失函数并运行计算梯度\n",
    "                valid_loss += running_loss.item()\n",
    "                valid_steps += 1\n",
    "        # endregion\n",
    "        \n",
    "        min_loss = min(min_loss, valid_loss / valid_steps)\n",
    "        trial.report(valid_loss / valid_steps, epoch)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "                \n",
    "    return min_loss\n",
    "\n",
    "study = optuna.create_study(study_name=\"ESM650M-Attention-Subtration-4-16\",\n",
    "                            pruner=optuna.pruners.HyperbandPruner(),\n",
    "                            direction=\"minimize\",\n",
    "                            storage=\"sqlite:///db.sqlite3\",\n",
    "                            load_if_exists=True)\n",
    "study.optimize(lambda trial: objective(trial, train_dataset), n_trials=300)"
   ],
   "id": "a4852b68e9d8c49",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-16 22:31:48,158] A new study created in RDB with name: ESM650M-Attention-Subtration-4-16\n",
      "[I 2024-04-16 22:32:15,420] Trial 0 finished with value: 4.573757886886597 and parameters: {'dropout': 0.507871140048874, 'num_heads': 1, 'bias': True, 'optimizer': 'SGD', 'lr': 0.017166355607103532, 'weight_decay': 0.0006680900918200253, 'batch_size': 64}. Best is trial 0 with value: 4.573757886886597.\n",
      "[I 2024-04-16 22:32:43,316] Trial 1 finished with value: 4.328893423080444 and parameters: {'dropout': 0.528501308279987, 'num_heads': 1, 'bias': False, 'optimizer': 'RMSprop', 'lr': 0.0006064444680349237, 'weight_decay': 0.007402089667701735, 'batch_size': 64}. Best is trial 1 with value: 4.328893423080444.\n",
      "[I 2024-04-16 22:33:41,100] Trial 2 finished with value: 4.556233584880829 and parameters: {'dropout': 0.5023329008481388, 'num_heads': 8, 'bias': True, 'optimizer': 'Adam', 'lr': 0.00792353798650842, 'weight_decay': 0.009694300903290449, 'batch_size': 32}. Best is trial 1 with value: 4.328893423080444.\n",
      "[I 2024-04-16 22:33:41,487] Trial 3 pruned. \n",
      "[I 2024-04-16 22:33:41,889] Trial 4 pruned. \n",
      "[I 2024-04-16 22:33:42,181] Trial 5 pruned. \n",
      "[I 2024-04-16 22:33:43,256] Trial 6 pruned. \n",
      "[I 2024-04-16 22:33:43,563] Trial 7 pruned. \n",
      "[I 2024-04-16 22:33:44,644] Trial 8 pruned. \n",
      "[I 2024-04-16 22:33:45,014] Trial 9 pruned. \n",
      "[I 2024-04-16 22:33:45,290] Trial 10 pruned. \n",
      "[I 2024-04-16 22:33:45,984] Trial 11 pruned. \n",
      "[I 2024-04-16 22:34:35,673] Trial 12 finished with value: 4.298589706420898 and parameters: {'dropout': 0.6346456761844814, 'num_heads': 8, 'bias': True, 'optimizer': 'RMSprop', 'lr': 0.007186242877695859, 'weight_decay': 0.01502066837526429, 'batch_size': 32}. Best is trial 12 with value: 4.298589706420898.\n",
      "[I 2024-04-16 22:34:36,925] Trial 13 pruned. \n",
      "[I 2024-04-16 22:34:37,146] Trial 14 pruned. \n",
      "[I 2024-04-16 22:34:37,469] Trial 15 pruned. \n",
      "[I 2024-04-16 22:34:38,004] Trial 16 pruned. \n",
      "[I 2024-04-16 22:34:38,354] Trial 17 pruned. \n",
      "[I 2024-04-16 22:34:43,439] Trial 18 pruned. \n",
      "[I 2024-04-16 22:35:33,485] Trial 19 finished with value: 4.404791831970215 and parameters: {'dropout': 0.6402251001298893, 'num_heads': 1, 'bias': True, 'optimizer': 'RMSprop', 'lr': 0.03336606739845422, 'weight_decay': 0.00011213868126218561, 'batch_size': 32}. Best is trial 12 with value: 4.298589706420898.\n",
      "[I 2024-04-16 22:35:33,783] Trial 20 pruned. \n",
      "[I 2024-04-16 22:35:34,561] Trial 21 pruned. \n",
      "[I 2024-04-16 22:35:36,506] Trial 22 pruned. \n",
      "[I 2024-04-16 22:35:36,915] Trial 23 pruned. \n",
      "[I 2024-04-16 22:35:37,676] Trial 24 pruned. \n",
      "[I 2024-04-16 22:35:38,073] Trial 25 pruned. \n",
      "[I 2024-04-16 22:35:38,804] Trial 26 pruned. \n",
      "[I 2024-04-16 22:35:39,256] Trial 27 pruned. \n",
      "[I 2024-04-16 22:35:40,319] Trial 28 pruned. \n",
      "[I 2024-04-16 22:35:40,769] Trial 29 pruned. \n",
      "[I 2024-04-16 22:35:41,603] Trial 30 pruned. \n",
      "[I 2024-04-16 22:35:43,605] Trial 31 pruned. \n",
      "[I 2024-04-16 22:35:44,110] Trial 32 pruned. \n",
      "[I 2024-04-16 22:35:44,611] Trial 33 pruned. \n",
      "[I 2024-04-16 22:35:45,468] Trial 34 pruned. \n",
      "[I 2024-04-16 22:35:46,347] Trial 35 pruned. \n",
      "[I 2024-04-16 22:35:46,745] Trial 36 pruned. \n",
      "[I 2024-04-16 22:35:47,316] Trial 37 pruned. \n",
      "[I 2024-04-16 22:35:47,784] Trial 38 pruned. \n",
      "[I 2024-04-16 22:35:48,950] Trial 39 pruned. \n",
      "[I 2024-04-16 22:35:49,780] Trial 40 pruned. \n",
      "[I 2024-04-16 22:35:50,069] Trial 41 pruned. \n",
      "[I 2024-04-16 22:35:51,044] Trial 42 pruned. \n",
      "[I 2024-04-16 22:35:51,339] Trial 43 pruned. \n",
      "[I 2024-04-16 22:35:51,808] Trial 44 pruned. \n",
      "[I 2024-04-16 22:35:52,356] Trial 45 pruned. \n",
      "[I 2024-04-16 22:35:52,894] Trial 46 pruned. \n",
      "[I 2024-04-16 22:35:54,752] Trial 47 pruned. \n",
      "[I 2024-04-16 22:36:28,893] Trial 48 finished with value: 4.390208721160889 and parameters: {'dropout': 0.623350432614944, 'num_heads': 8, 'bias': True, 'optimizer': 'SGD', 'lr': 0.0038478937950754285, 'weight_decay': 0.0035566642517084004, 'batch_size': 64}. Best is trial 12 with value: 4.298589706420898.\n",
      "[I 2024-04-16 22:36:29,816] Trial 49 pruned. \n",
      "[I 2024-04-16 22:36:31,547] Trial 50 pruned. \n",
      "[I 2024-04-16 22:36:32,611] Trial 51 pruned. \n",
      "[I 2024-04-16 22:36:33,691] Trial 52 pruned. \n",
      "[I 2024-04-16 22:36:34,177] Trial 53 pruned. \n",
      "[I 2024-04-16 22:36:34,520] Trial 54 pruned. \n",
      "[I 2024-04-16 22:36:34,808] Trial 55 pruned. \n",
      "[I 2024-04-16 22:36:35,465] Trial 56 pruned. \n",
      "[I 2024-04-16 22:36:35,679] Trial 57 pruned. \n",
      "[I 2024-04-16 22:36:36,025] Trial 58 pruned. \n",
      "[I 2024-04-16 22:36:36,261] Trial 59 pruned. \n",
      "[I 2024-04-16 22:36:36,612] Trial 60 pruned. \n",
      "[I 2024-04-16 22:36:37,417] Trial 61 pruned. \n",
      "[I 2024-04-16 22:36:37,793] Trial 62 pruned. \n",
      "[I 2024-04-16 22:36:38,100] Trial 63 pruned. \n",
      "[I 2024-04-16 22:36:38,812] Trial 64 pruned. \n",
      "[I 2024-04-16 22:36:39,180] Trial 65 pruned. \n",
      "[I 2024-04-16 22:36:39,389] Trial 66 pruned. \n",
      "[I 2024-04-16 22:36:40,765] Trial 67 pruned. \n",
      "[I 2024-04-16 22:36:41,119] Trial 68 pruned. \n",
      "[I 2024-04-16 22:36:41,425] Trial 69 pruned. \n",
      "[I 2024-04-16 22:37:31,518] Trial 70 finished with value: 4.33608078956604 and parameters: {'dropout': 0.20344421751589645, 'num_heads': 1, 'bias': False, 'optimizer': 'RMSprop', 'lr': 0.003650322011514292, 'weight_decay': 0.021507359115022592, 'batch_size': 32}. Best is trial 12 with value: 4.298589706420898.\n",
      "[I 2024-04-16 22:37:31,989] Trial 71 pruned. \n",
      "[I 2024-04-16 22:37:32,445] Trial 72 pruned. \n",
      "[I 2024-04-16 22:37:37,266] Trial 73 pruned. \n",
      "[I 2024-04-16 22:37:39,016] Trial 74 pruned. \n",
      "[I 2024-04-16 22:37:39,825] Trial 75 pruned. \n",
      "[I 2024-04-16 22:37:40,584] Trial 76 pruned. \n",
      "[I 2024-04-16 22:37:40,891] Trial 77 pruned. \n",
      "[I 2024-04-16 22:37:41,549] Trial 78 pruned. \n",
      "[I 2024-04-16 22:37:48,942] Trial 79 pruned. \n",
      "[I 2024-04-16 22:37:49,379] Trial 80 pruned. \n",
      "[I 2024-04-16 22:37:50,160] Trial 81 pruned. \n",
      "[I 2024-04-16 22:37:50,532] Trial 82 pruned. \n",
      "[I 2024-04-16 22:37:50,770] Trial 83 pruned. \n",
      "[I 2024-04-16 22:37:51,147] Trial 84 pruned. \n",
      "[I 2024-04-16 22:37:51,395] Trial 85 pruned. \n",
      "[I 2024-04-16 22:38:43,309] Trial 86 finished with value: 4.268125534057617 and parameters: {'dropout': 0.6827809405241674, 'num_heads': 4, 'bias': True, 'optimizer': 'SGD', 'lr': 0.002987921026049736, 'weight_decay': 0.017273522094810475, 'batch_size': 32}. Best is trial 86 with value: 4.268125534057617.\n",
      "[I 2024-04-16 22:38:43,710] Trial 87 pruned. \n",
      "[I 2024-04-16 22:38:44,490] Trial 88 pruned. \n",
      "[I 2024-04-16 22:38:44,973] Trial 89 pruned. \n",
      "[I 2024-04-16 22:38:45,792] Trial 90 pruned. \n",
      "[I 2024-04-16 22:38:47,343] Trial 91 pruned. \n",
      "[I 2024-04-16 22:38:47,801] Trial 92 pruned. \n",
      "[I 2024-04-16 22:38:48,477] Trial 93 pruned. \n",
      "[I 2024-04-16 22:38:49,408] Trial 94 pruned. \n",
      "[I 2024-04-16 22:38:49,847] Trial 95 pruned. \n",
      "[I 2024-04-16 22:38:50,135] Trial 96 pruned. \n",
      "[I 2024-04-16 22:38:51,912] Trial 97 pruned. \n",
      "[I 2024-04-16 22:38:52,433] Trial 98 pruned. \n",
      "[I 2024-04-16 22:38:53,109] Trial 99 pruned. \n",
      "[I 2024-04-16 22:38:53,596] Trial 100 pruned. \n",
      "[I 2024-04-16 22:38:54,057] Trial 101 pruned. \n",
      "[I 2024-04-16 22:38:54,508] Trial 102 pruned. \n",
      "[I 2024-04-16 22:38:56,223] Trial 103 pruned. \n",
      "[I 2024-04-16 22:39:00,839] Trial 104 pruned. \n",
      "[I 2024-04-16 22:39:01,699] Trial 105 pruned. \n",
      "[I 2024-04-16 22:39:02,148] Trial 106 pruned. \n",
      "[I 2024-04-16 22:39:03,143] Trial 107 pruned. \n",
      "[I 2024-04-16 22:39:33,823] Trial 108 pruned. \n",
      "[I 2024-04-16 22:39:34,612] Trial 109 pruned. \n",
      "[I 2024-04-16 22:39:37,998] Trial 110 pruned. \n",
      "[I 2024-04-16 22:39:38,375] Trial 111 pruned. \n",
      "[I 2024-04-16 22:39:38,725] Trial 112 pruned. \n",
      "[I 2024-04-16 22:39:39,051] Trial 113 pruned. \n",
      "[I 2024-04-16 22:39:40,087] Trial 114 pruned. \n",
      "[I 2024-04-16 22:39:40,449] Trial 115 pruned. \n",
      "[I 2024-04-16 22:39:40,853] Trial 116 pruned. \n",
      "[I 2024-04-16 22:39:41,226] Trial 117 pruned. \n",
      "[I 2024-04-16 22:39:41,442] Trial 118 pruned. \n",
      "[I 2024-04-16 22:39:42,692] Trial 119 pruned. \n",
      "[I 2024-04-16 22:39:43,075] Trial 120 pruned. \n",
      "[I 2024-04-16 22:39:43,634] Trial 121 pruned. \n",
      "[I 2024-04-16 22:39:43,996] Trial 122 pruned. \n",
      "[I 2024-04-16 22:39:53,142] Trial 123 pruned. \n",
      "[I 2024-04-16 22:39:53,680] Trial 124 pruned. \n",
      "[I 2024-04-16 22:39:54,227] Trial 125 pruned. \n",
      "[I 2024-04-16 22:39:54,553] Trial 126 pruned. \n",
      "[I 2024-04-16 22:39:54,925] Trial 127 pruned. \n",
      "[I 2024-04-16 22:39:55,271] Trial 128 pruned. \n",
      "[I 2024-04-16 22:39:56,570] Trial 129 pruned. \n",
      "[I 2024-04-16 22:39:56,937] Trial 130 pruned. \n",
      "[I 2024-04-16 22:39:57,475] Trial 131 pruned. \n",
      "[I 2024-04-16 22:39:58,073] Trial 132 pruned. \n",
      "[I 2024-04-16 22:39:59,323] Trial 133 pruned. \n",
      "[I 2024-04-16 22:39:59,654] Trial 134 pruned. \n",
      "[I 2024-04-16 22:39:59,978] Trial 135 pruned. \n",
      "[I 2024-04-16 22:40:01,147] Trial 136 pruned. \n",
      "[I 2024-04-16 22:40:01,391] Trial 137 pruned. \n",
      "[I 2024-04-16 22:40:02,031] Trial 138 pruned. \n",
      "[I 2024-04-16 22:40:02,567] Trial 139 pruned. \n",
      "[I 2024-04-16 22:40:02,827] Trial 140 pruned. \n",
      "[I 2024-04-16 22:40:03,202] Trial 141 pruned. \n",
      "[I 2024-04-16 22:40:06,570] Trial 142 pruned. \n",
      "[I 2024-04-16 22:40:07,191] Trial 143 pruned. \n",
      "[I 2024-04-16 22:40:07,788] Trial 144 pruned. \n",
      "[I 2024-04-16 22:40:09,110] Trial 145 pruned. \n",
      "[I 2024-04-16 22:40:09,720] Trial 146 pruned. \n",
      "[I 2024-04-16 22:40:09,972] Trial 147 pruned. \n",
      "[I 2024-04-16 22:40:10,277] Trial 148 pruned. \n",
      "[I 2024-04-16 22:40:10,836] Trial 149 pruned. \n",
      "[I 2024-04-16 22:40:11,054] Trial 150 pruned. \n",
      "[I 2024-04-16 22:40:11,433] Trial 151 pruned. \n",
      "[I 2024-04-16 22:40:11,817] Trial 152 pruned. \n",
      "[I 2024-04-16 22:40:12,168] Trial 153 pruned. \n",
      "[I 2024-04-16 22:40:12,545] Trial 154 pruned. \n",
      "[I 2024-04-16 22:40:13,115] Trial 155 pruned. \n",
      "[I 2024-04-16 22:40:23,137] Trial 156 pruned. \n",
      "[I 2024-04-16 22:40:23,451] Trial 157 pruned. \n",
      "[I 2024-04-16 22:40:25,426] Trial 158 pruned. \n",
      "[I 2024-04-16 22:40:26,590] Trial 159 pruned. \n",
      "[I 2024-04-16 22:40:26,838] Trial 160 pruned. \n",
      "[I 2024-04-16 22:40:27,101] Trial 161 pruned. \n",
      "[I 2024-04-16 22:40:27,366] Trial 162 pruned. \n",
      "[I 2024-04-16 22:40:27,641] Trial 163 pruned. \n",
      "[I 2024-04-16 22:40:58,340] Trial 164 pruned. \n",
      "[I 2024-04-16 22:40:59,235] Trial 165 pruned. \n",
      "[I 2024-04-16 22:41:00,296] Trial 166 pruned. \n",
      "[I 2024-04-16 22:41:01,229] Trial 167 pruned. \n",
      "[I 2024-04-16 22:41:02,165] Trial 168 pruned. \n",
      "[I 2024-04-16 22:41:03,021] Trial 169 pruned. \n",
      "[I 2024-04-16 22:41:05,220] Trial 170 pruned. \n",
      "[I 2024-04-16 22:41:05,617] Trial 171 pruned. \n",
      "[I 2024-04-16 22:42:08,088] Trial 172 finished with value: 4.1955671310424805 and parameters: {'dropout': 0.6780081628303054, 'num_heads': 4, 'bias': True, 'optimizer': 'Adam', 'lr': 0.020908934977476045, 'weight_decay': 0.022402476301294914, 'batch_size': 64}. Best is trial 172 with value: 4.1955671310424805.\n",
      "[I 2024-04-16 22:42:08,562] Trial 173 pruned. \n",
      "[I 2024-04-16 22:42:09,067] Trial 174 pruned. \n",
      "[I 2024-04-16 22:42:10,482] Trial 175 pruned. \n",
      "[I 2024-04-16 22:42:11,227] Trial 176 pruned. \n",
      "[I 2024-04-16 22:42:11,935] Trial 177 pruned. \n",
      "[I 2024-04-16 22:42:12,957] Trial 178 pruned. \n",
      "[I 2024-04-16 22:42:25,920] Trial 179 pruned. \n",
      "[I 2024-04-16 22:42:26,515] Trial 180 pruned. \n",
      "[I 2024-04-16 22:42:27,168] Trial 181 pruned. \n",
      "[I 2024-04-16 22:42:40,382] Trial 182 pruned. \n",
      "[I 2024-04-16 22:42:40,883] Trial 183 pruned. \n",
      "[I 2024-04-16 22:42:41,363] Trial 184 pruned. \n",
      "[I 2024-04-16 22:42:42,415] Trial 185 pruned. \n",
      "[I 2024-04-16 22:42:44,656] Trial 186 pruned. \n",
      "[I 2024-04-16 22:42:45,432] Trial 187 pruned. \n",
      "[I 2024-04-16 22:42:46,635] Trial 188 pruned. \n",
      "[I 2024-04-16 22:42:47,750] Trial 189 pruned. \n",
      "[I 2024-04-16 22:42:48,296] Trial 190 pruned. \n",
      "[I 2024-04-16 22:42:50,546] Trial 191 pruned. \n",
      "[I 2024-04-16 22:42:51,733] Trial 192 pruned. \n",
      "[I 2024-04-16 22:42:52,811] Trial 193 pruned. \n",
      "[I 2024-04-16 22:42:53,484] Trial 194 pruned. \n",
      "[I 2024-04-16 22:42:54,550] Trial 195 pruned. \n",
      "[I 2024-04-16 22:42:55,154] Trial 196 pruned. \n",
      "[I 2024-04-16 22:42:56,234] Trial 197 pruned. \n",
      "[I 2024-04-16 22:43:00,815] Trial 198 pruned. \n",
      "[I 2024-04-16 22:43:01,171] Trial 199 pruned. \n",
      "[I 2024-04-16 22:43:01,721] Trial 200 pruned. \n",
      "[I 2024-04-16 22:43:02,090] Trial 201 pruned. \n",
      "[I 2024-04-16 22:43:02,463] Trial 202 pruned. \n",
      "[I 2024-04-16 22:43:03,023] Trial 203 pruned. \n",
      "[I 2024-04-16 22:43:03,708] Trial 204 pruned. \n",
      "[I 2024-04-16 22:43:08,318] Trial 205 pruned. \n",
      "[I 2024-04-16 22:43:09,122] Trial 206 pruned. \n",
      "[I 2024-04-16 22:43:15,810] Trial 207 pruned. \n",
      "[I 2024-04-16 22:43:16,257] Trial 208 pruned. \n",
      "[I 2024-04-16 22:44:17,720] Trial 209 pruned. \n",
      "[I 2024-04-16 22:44:18,822] Trial 210 pruned. \n",
      "[I 2024-04-16 22:44:22,806] Trial 211 pruned. \n",
      "[I 2024-04-16 22:44:23,958] Trial 212 pruned. \n",
      "[I 2024-04-16 22:44:44,622] Trial 213 pruned. \n",
      "[I 2024-04-16 22:44:47,614] Trial 214 pruned. \n",
      "[I 2024-04-16 22:44:48,158] Trial 215 pruned. \n",
      "[I 2024-04-16 22:44:48,729] Trial 216 pruned. \n",
      "[I 2024-04-16 22:45:09,526] Trial 217 pruned. \n",
      "[I 2024-04-16 22:45:10,498] Trial 218 pruned. \n",
      "[I 2024-04-16 22:45:11,100] Trial 219 pruned. \n",
      "[I 2024-04-16 22:45:12,099] Trial 220 pruned. \n",
      "[I 2024-04-16 22:45:13,064] Trial 221 pruned. \n",
      "[I 2024-04-16 22:45:13,580] Trial 222 pruned. \n",
      "[I 2024-04-16 22:45:14,446] Trial 223 pruned. \n",
      "[I 2024-04-16 22:45:17,134] Trial 224 pruned. \n",
      "[I 2024-04-16 22:45:19,017] Trial 225 pruned. \n",
      "[I 2024-04-16 22:45:19,774] Trial 226 pruned. \n",
      "[I 2024-04-16 22:45:20,951] Trial 227 pruned. \n",
      "[I 2024-04-16 22:45:22,027] Trial 228 pruned. \n",
      "[I 2024-04-16 22:45:29,244] Trial 229 pruned. \n",
      "[I 2024-04-16 22:45:30,174] Trial 230 pruned. \n",
      "[I 2024-04-16 22:45:32,405] Trial 231 pruned. \n",
      "[I 2024-04-16 22:45:33,248] Trial 232 pruned. \n",
      "[I 2024-04-16 22:45:33,754] Trial 233 pruned. \n",
      "[I 2024-04-16 22:46:27,876] Trial 234 pruned. \n",
      "[I 2024-04-16 22:46:34,552] Trial 235 pruned. \n",
      "[I 2024-04-16 22:46:35,039] Trial 236 pruned. \n",
      "[I 2024-04-16 22:46:36,098] Trial 237 pruned. \n",
      "[I 2024-04-16 22:46:36,575] Trial 238 pruned. \n",
      "[I 2024-04-16 22:46:37,522] Trial 239 pruned. \n",
      "[I 2024-04-16 22:46:37,981] Trial 240 pruned. \n",
      "[I 2024-04-16 22:46:38,458] Trial 241 pruned. \n",
      "[I 2024-04-16 22:46:46,674] Trial 242 pruned. \n",
      "[I 2024-04-16 22:46:54,693] Trial 243 pruned. \n",
      "[I 2024-04-16 22:47:55,184] Trial 244 pruned. \n",
      "[I 2024-04-16 22:48:04,596] Trial 245 pruned. \n",
      "[I 2024-04-16 22:48:05,529] Trial 246 pruned. \n",
      "[I 2024-04-16 22:48:13,259] Trial 247 pruned. \n",
      "[I 2024-04-16 22:48:33,940] Trial 248 pruned. \n",
      "[I 2024-04-16 22:48:35,144] Trial 249 pruned. \n",
      "[I 2024-04-16 22:48:36,218] Trial 250 pruned. \n",
      "[I 2024-04-16 22:48:36,912] Trial 251 pruned. \n",
      "[I 2024-04-16 22:48:39,834] Trial 252 pruned. \n",
      "[I 2024-04-16 22:48:42,404] Trial 253 pruned. \n",
      "[I 2024-04-16 22:48:44,863] Trial 254 pruned. \n",
      "[I 2024-04-16 22:49:04,837] Trial 255 pruned. \n",
      "[I 2024-04-16 22:49:06,545] Trial 256 pruned. \n",
      "[I 2024-04-16 22:49:12,824] Trial 257 pruned. \n",
      "[I 2024-04-16 22:49:14,789] Trial 258 pruned. \n",
      "[I 2024-04-16 22:49:15,797] Trial 259 pruned. \n",
      "[I 2024-04-16 22:49:16,683] Trial 260 pruned. \n",
      "[I 2024-04-16 22:49:20,410] Trial 261 pruned. \n",
      "[I 2024-04-16 22:49:22,790] Trial 262 pruned. \n",
      "[I 2024-04-16 22:49:23,320] Trial 263 pruned. \n",
      "[I 2024-04-16 22:49:24,496] Trial 264 pruned. \n",
      "[I 2024-04-16 22:49:26,128] Trial 265 pruned. \n",
      "[I 2024-04-16 22:49:27,157] Trial 266 pruned. \n",
      "[I 2024-04-16 22:49:28,741] Trial 267 pruned. \n",
      "[I 2024-04-16 22:49:29,997] Trial 268 pruned. \n",
      "[I 2024-04-16 22:49:30,570] Trial 269 pruned. \n",
      "[I 2024-04-16 22:49:30,891] Trial 270 pruned. \n",
      "[I 2024-04-16 22:49:31,917] Trial 271 pruned. \n",
      "[I 2024-04-16 22:49:32,291] Trial 272 pruned. \n",
      "[I 2024-04-16 22:49:34,405] Trial 273 pruned. \n",
      "[I 2024-04-16 22:49:34,818] Trial 274 pruned. \n",
      "[I 2024-04-16 22:49:35,265] Trial 275 pruned. \n",
      "[I 2024-04-16 22:49:37,366] Trial 276 pruned. \n",
      "[I 2024-04-16 22:49:41,405] Trial 277 pruned. \n",
      "[I 2024-04-16 22:49:42,276] Trial 278 pruned. \n",
      "[I 2024-04-16 22:49:42,955] Trial 279 pruned. \n",
      "[I 2024-04-16 22:49:43,399] Trial 280 pruned. \n",
      "[I 2024-04-16 22:49:45,590] Trial 281 pruned. \n",
      "[I 2024-04-16 22:49:46,683] Trial 282 pruned. \n",
      "[I 2024-04-16 22:49:47,810] Trial 283 pruned. \n",
      "[I 2024-04-16 22:49:48,860] Trial 284 pruned. \n",
      "[I 2024-04-16 22:49:52,413] Trial 285 pruned. \n",
      "[I 2024-04-16 22:49:53,410] Trial 286 pruned. \n",
      "[I 2024-04-16 22:49:53,971] Trial 287 pruned. \n",
      "[I 2024-04-16 22:49:54,508] Trial 288 pruned. \n",
      "[I 2024-04-16 22:49:56,340] Trial 289 pruned. \n",
      "[I 2024-04-16 22:49:59,662] Trial 290 pruned. \n",
      "[I 2024-04-16 22:50:01,688] Trial 291 pruned. \n",
      "[I 2024-04-16 22:50:02,683] Trial 292 pruned. \n",
      "[I 2024-04-16 22:50:03,226] Trial 293 pruned. \n",
      "[I 2024-04-16 22:50:04,064] Trial 294 pruned. \n",
      "[I 2024-04-16 22:50:06,238] Trial 295 pruned. \n",
      "[I 2024-04-16 22:50:07,000] Trial 296 pruned. \n",
      "[I 2024-04-16 22:50:24,575] Trial 297 pruned. \n",
      "[I 2024-04-16 22:50:25,057] Trial 298 pruned. \n",
      "[I 2024-04-16 22:50:25,690] Trial 299 pruned. \n"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
