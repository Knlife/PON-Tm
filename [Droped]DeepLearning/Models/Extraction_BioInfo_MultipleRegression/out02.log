nohup: ignoring input
NVIDIA A100-PCIE-40GB
当前使用设备：  NVIDIA A100-PCIE-40GB
===正在从训练集版本为ProThermDB_Common、训练集版本为ProThermDBTest_Common的原始数据集中进行数据清洗和生物特征提取工作===
1.预处理训练集数据...
删除数据缺失行及非法行共计0行
丢弃pH/Tm的缺失值
前一数据集采用了后一数据集中的0条数据，现已删除
获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件
删除了0个非法长度的蛋白质，当前蛋白质长度被限制在(0, 5000)
不针对突变位点上下文进行截取
2.预处理测试集数据...
删除数据缺失行及非法行共计0行
丢弃pH/Tm的缺失值
获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件
删除了0个非法长度的蛋白质，当前蛋白质长度被限制在(0, 5000)
不针对突变位点上下文进行截取
3.为训练集数据提取生物特征...
获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件
获取[aaindex特征].....该数据集已经经过处理，直接使用缓存文件
4.为测试集数据提取生物特征...
获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件
获取[aaindex特征].....该数据集已经经过处理，直接使用缓存文件
6.从全数据集中提取生物特征集、标签集和基本信息集...
7.数据清洗和生物特征提取工作完成==>
当前显存用量: 0.0
Acting on ESM3B...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/public/home/yyang/anaconda3/envs/Pon-DT/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  50%|█████     | 1/2 [00:19<00:19, 19.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00,  9.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 11.10s/it]
Some weights of EsmModel were not initialized from the model checkpoint at DeepLearning/EmbeddingModels/ESM-2/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/4 [00:00<?, ?it/s]