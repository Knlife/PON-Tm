{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ESM-2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29674f02d7bcfb14"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.引用模块"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2448c83e5abe87bc"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:05:42.336082Z",
     "start_time": "2024-04-03T13:05:40.462184Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "os.chdir(\"D:/WorkPath/PycharmProjects/MutTm-pred\")\n",
    "from Dataset.Process4Dataset.DatasetCeator4PonDT import Dataset4MutTm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.导入数据"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9bf9ebb4a44f0f0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===正在从训练集版本为ProThermDB_withpHTm、训练集版本为ProThermDBTest_withpHTm的原始数据集中进行数据清洗和生物特征提取工作===\n",
      "1.预处理训练集数据...\n",
      "删除数据缺失行及非法行共计1行\n",
      "丢弃pH/Tm的缺失值\n",
      "前一数据集采用了后一数据集中的0条数据，现已删除\n",
      "获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "删除了0个非法长度的蛋白质，当前蛋白质长度被限制在(50, 5000)\n",
      "2.预处理测试集数据...\n",
      "删除数据缺失行及非法行共计0行\n",
      "丢弃pH/Tm的缺失值\n",
      "获取[序列]信息.....该数据集已经经过处理，直接使用缓存文件\n",
      "删除了0个非法长度的蛋白质，当前蛋白质长度被限制在(50, 5000)\n",
      "3.为训练集数据提取生物特征...\n",
      "获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "获取[aaindex特征].....获取[group特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "获取[pssm]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "获取[sift4g]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "获取[param]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "4.为测试集数据提取生物特征...\n",
      "获取[neighbor特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "获取[aaindex特征].....获取[group特征].....该数据集已经经过处理，直接使用缓存文件\n",
      "获取[pssm]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "获取[sift4g]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "获取[param]特征.....该数据集已经经过处理，直接使用缓存文件\n",
      "5.利用GO富集分析从训练集和测试集中提取LR与PA值\n",
      "获取[GO]特征....."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4228/4228 [00:00<00:00, 28011.94it/s]\n",
      "100%|██████████| 218/218 [00:00<00:00, 27251.16it/s]\n",
      "100%|██████████| 4228/4228 [00:00<00:00, 10339.06it/s]\n",
      "100%|██████████| 218/218 [00:00<00:00, 10381.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.从全数据集中提取生物特征集、标签集和基本信息集...\n",
      "7.数据清洗和生物特征提取工作完成==>\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset4MutTm(package_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\\Process4Dataset\",\n",
    "                        train_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\\BasicData\\ProThermDB\\pH-Tm\\excllent_ProThermDB_Training.csv\",\n",
    "                        test_dataset_path=r\"D:\\WorkPath\\PycharmProjects\\MutTm-pred\\Dataset\\BasicData\\ProThermDB\\pH-Tm\\excllent_ProThermDB_Testing.csv\",\n",
    "                        training_version=\"ProThermDB_withpHTm\",\n",
    "                        testing_version=\"ProThermDBTest_withpHTm\",\n",
    "                        selected_columns=[\"UniProt_ID\", \"Mutation\", \"pH\", \"Tm\", \"ΔTm\"],\n",
    "                        mult_mode=\"Average\",\n",
    "                        features=[\"neighbor\", \"sift4g\", \"rpm\", \"param\", \"aaindex\", \"group\", \"GO\"],\n",
    "                        R_path=r\"C:\\Program Files\\R\\R-4.3.2\",\n",
    "                        context_length=50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:05:44.518478Z",
     "start_time": "2024-04-03T13:05:42.337085Z"
    }
   },
   "id": "148df3a094fa2d1d",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.导入预训练模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21b24f06a13d8afd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "modelPath = \"DeepLearning/EmbeddingModels/ESM-2/esm2_t30_150M_UR50D\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=modelPath)\n",
    "model = AutoModel.from_pretrained(modelPath).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:05:45.268285Z",
     "start_time": "2024-04-03T13:05:44.518478Z"
    }
   },
   "id": "65e5227567842212",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 构建数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2243a3adab09e92"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_wild_tokenized = tokenizer(dataset.train_basic_set[\"WildSeq\"].to_list(), return_tensors=\"pt\", padding=False)\n",
    "test_wild_tokenized = tokenizer(dataset.test_basic_set[\"WildSeq\"].to_list(), return_tensors=\"pt\", padding=False)\n",
    "train_mutant_tokenized = tokenizer(dataset.train_basic_set[\"MutantSeq\"].to_list(), return_tensors=\"pt\", padding=False)\n",
    "test_mutant_tokenized = tokenizer(dataset.test_basic_set[\"MutantSeq\"].to_list(), return_tensors=\"pt\", padding=False)\n",
    "train_labels = np.array(dataset.train_label_set)\n",
    "test_labels = np.array(dataset.test_label_set)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\"wild_input_ids\": train_wild_tokenized[\"input_ids\"],\n",
    "                                   \"wild_attention_mask\": train_wild_tokenized[\"attention_mask\"],\n",
    "                                   \"labels\": train_labels,\n",
    "                                   \"mutant_input_ids\": train_mutant_tokenized[\"input_ids\"],\n",
    "                                   \"mutant_attention_mask\": train_mutant_tokenized[\"attention_mask\"]})\n",
    "test_dataset = Dataset.from_dict({\"wild_input_ids\": test_wild_tokenized[\"input_ids\"],\n",
    "                                  \"wild_attention_mask\": test_wild_tokenized[\"attention_mask\"],\n",
    "                                  \"labels\": test_labels,\n",
    "                                  \"mutant_input_ids\": test_mutant_tokenized[\"input_ids\"],\n",
    "                                  \"mutant_attention_mask\": test_mutant_tokenized[\"attention_mask\"]})\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:05:45.953884Z",
     "start_time": "2024-04-03T13:05:45.269285Z"
    }
   },
   "id": "d75ccaa7e374024f",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.自定义模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2342c61ab01f284"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.nn import init\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:05:45.957397Z",
     "start_time": "2024-04-03T13:05:45.954885Z"
    }
   },
   "id": "2919e2b277da566",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.前馈多头注意力网络"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7fa2a9aa9643e6e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# PreAttention类\n",
    "class Attention(nn.Module):\n",
    "    # InitializationDataset:https://github.com/WenYanger/Contextual-Attention/blob/master/Attention_Pytorch.py\n",
    "    def __init__(self, input_shape):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.max_len = input_shape[1]\n",
    "        self.emb_size = input_shape[2]\n",
    "\n",
    "        # Change double to float\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.emb_size, 1))\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.max_len, 1))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'max_len={}, emb_size={}'.format(\n",
    "            self.max_len, self.emb_size\n",
    "        )\n",
    "\n",
    "    def forward(self, inp, mask=None):\n",
    "        # Here    sr should be [batch_size, time_step, emb_size]\n",
    "        #      mask should be [batch_size, time_step, 1]\n",
    "        W_bs = self.weight.unsqueeze(0).repeat(inp.size()[0], 1, 1).float()  # Copy the Attention Matrix for batch_size times\n",
    "        scores = torch.bmm(inp, W_bs)  # Dot product between input and attention matrix\n",
    "        scores = torch.tanh(scores)\n",
    "\n",
    "        # scores = Cal_Attention()(sr, self.weight, self.bias)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.long()\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        a_ = F.softmax(scores.squeeze(-1), dim=-1)\n",
    "        a = a_.unsqueeze(-1).repeat(1, 1, inp.size()[2])\n",
    "\n",
    "        weighted_input = inp * a\n",
    "\n",
    "        output = torch.sum(weighted_input, dim=1)\n",
    "\n",
    "        return output  # 不返回权重矩阵"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:05:45.962419Z",
     "start_time": "2024-04-03T13:05:45.957913Z"
    }
   },
   "id": "e1716525fe05c97e",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2.Main Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47d95503deb4c257"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 特征提取网络类\n",
    "class PonDT(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 length,\n",
    "                 embedding_model):\n",
    "        super(PonDT, self).__init__()\n",
    "\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "        # 特征提取模块\n",
    "        self.Input_Feature_Module = nn.Sequential(\n",
    "            Attention([None, length, 640]),\n",
    "            nn.BatchNorm1d(640, dtype=torch.float32),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # 回归模块\n",
    "        self.Fussion_Module = nn.Sequential(\n",
    "            nn.Linear(1280, 512, dtype=torch.float32), nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256, dtype=torch.float32), nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128, dtype=torch.float32), nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 32, dtype=torch.float32), nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    def forward(self, wild_ids, wild_mask, mutant_ids, mutant_mask):\n",
    "        # 预训练特征模块\n",
    "        wild_output = self.embedding_model(input_ids=wild_ids, attention_mask=wild_mask).last_hidden_state\n",
    "        mutant_output = self.embedding_model(input_ids=mutant_ids, attention_mask=mutant_mask).last_hidden_state\n",
    "        # 特征提取模块\n",
    "        wild_output = self.Input_Feature_Module(wild_output)\n",
    "        mutant_output = self.Input_Feature_Module(mutant_output)\n",
    "\n",
    "        # 拼接机器学习特征与深度特征\n",
    "        combination = torch.cat((wild_output, mutant_output), dim=1)\n",
    "\n",
    "        # MLP回归预测\n",
    "        out = self.Fussion_Module(combination)\n",
    "\n",
    "        # output\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:05:45.967454Z",
     "start_time": "2024-04-03T13:05:45.962932Z"
    }
   },
   "id": "ee4696f60e6d5c45",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义训练参数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "127740bf2018f2b4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "pondt = PonDT(length=52, embedding_model=model).to(device)\n",
    "loss_fn = torch.nn.L1Loss().to(device)\n",
    "optimizer = torch.optim.Adam(params=pondt.parameters(),\n",
    "                             lr=1e-3,\n",
    "                             betas=(0.9, 0.999),\n",
    "                             eps=1e-3)\n",
    "num_epochs = 1000\n",
    "num_training_steps = num_epochs * len(train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:05:46.443134Z",
     "start_time": "2024-04-03T13:05:45.967454Z"
    }
   },
   "id": "5d97c0cced8ca865",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c52bfa30da157955"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1320 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f81e81a9ac144ec88cb0707c20fc60fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tqdm(range(num_training_steps)) as progress_bar:\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            wild_input_ids = torch.stack(batch[\"wild_input_ids\"], dim=1).to(device)\n",
    "            wild_attention_mask = torch.stack(batch[\"wild_attention_mask\"], dim=1).to(device)\n",
    "            mutant_input_ids = torch.stack(batch[\"mutant_input_ids\"], dim=1).to(device)\n",
    "            mutant_attention_mask = torch.stack(batch[\"mutant_attention_mask\"], dim=1).to(device)\n",
    "            outputs = pondt(wild_input_ids, wild_attention_mask, mutant_input_ids, mutant_attention_mask)\n",
    "            labels = batch[\"labels\"].to(device).unsqueeze(1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.requires_grad_(True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            progress_bar.update(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:14:19.749840Z",
     "start_time": "2024-04-03T13:09:19.020586Z"
    }
   },
   "id": "c222c367520c9aae",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "a = torch.Tensor([3, 2, 1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:52.153303Z",
     "start_time": "2024-04-03T13:49:52.150694Z"
    }
   },
   "id": "c04646bd15c7846c",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:50:00.732537Z",
     "start_time": "2024-04-03T13:50:00.729389Z"
    }
   },
   "id": "1f26849c661f3a0f",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "b = a.unsqueeze(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:50:09.621059Z",
     "start_time": "2024-04-03T13:50:09.618430Z"
    }
   },
   "id": "922a94f56f78a949",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 1])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:50:28.464453Z",
     "start_time": "2024-04-03T13:50:28.461319Z"
    }
   },
   "id": "cac50c00b92fba25",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 2)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a.size()), len(b.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:50:41.180359Z",
     "start_time": "2024-04-03T13:50:41.177136Z"
    }
   },
   "id": "a3675fae9ef78b06",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "new = batch[\"wild_input_ids\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:52:05.266221Z",
     "start_time": "2024-04-03T13:52:05.264344Z"
    }
   },
   "id": "3d1508498866c436",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "old = torch.stack(batch[\"wild_input_ids\"], dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:52:32.602425Z",
     "start_time": "2024-04-03T13:52:32.599316Z"
    }
   },
   "id": "a92564af94caa8ab",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "list"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:52:58.758947Z",
     "start_time": "2024-04-03T13:52:58.756366Z"
    }
   },
   "id": "72f13006ce5a9731",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Tensor"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(old)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:53:09.468341Z",
     "start_time": "2024-04-03T13:53:09.464341Z"
    }
   },
   "id": "29a9ebf395e997d3",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c07ee53e30d700bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
